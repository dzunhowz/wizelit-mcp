import asyncio
import difflib
import os
import time
import contextlib
from typing import Dict, Any
from utils.bedrock_config import normalize_aws_env, resolve_bedrock_model_id

# FastMCP - use published SDK
from wizelit_sdk.agent_wrapper import WizelitAgentWrapper, Job

# Database (optional - for persistence)
try:
    from database import DatabaseManager

    db_manager = DatabaseManager()
except ImportError:
    db_manager = None
    print("Warning: DatabaseManager not available. Job persistence disabled.")

# CrewAI
from crewai import Agent, Task, Crew
from crewai.llm import LLM
from crewai.process import Process

# Initialize FastMCP with database manager and streaming
enable_streaming = os.getenv("ENABLE_LOG_STREAMING", "true").lower() == "true"
mcp = WizelitAgentWrapper(
    "RefactoringCrewAgent",
    port=1337,
    transport="sse",
    db_manager=db_manager,
    enable_streaming=enable_streaming,
)


def _html_diff_viewer(from_lines: list[str], to_lines: list[str]) -> str:
    """Compare two texts and generate an HTML difference view."""
    # Create an HtmlDiff instance
    # You can use parameters like wrapcolumn=80 to control line wrapping
    differ = difflib.HtmlDiff(wrapcolumn=40)

    # Generate the HTML output (as a single string)
    # make_table includes HTML table boilerplate
    html_diff = differ.make_table(
        from_lines, to_lines, fromdesc="Original", todesc="Modified"
    )

    return html_diff


def _extract_lines(text: str) -> list[str]:
    # Break incoming message into an array of text lines (non-empty)
    lines = [l for l in text.splitlines() if l.strip() != ""]
    # Fallback to original content if splitting yields nothing (e.g., only whitespace)
    if not lines:
        lines = [text]
    return lines


async def _run_refactoring_crew(job: Job, code: str, instruction: str):
    """
    Refactor code using CrewAI in two steps:
    1) Architect-style analysis + plan
    2) Code-only refactor output

    NOTE: We explicitly configure a Bedrock-backed model for CrewAI so it
    doesn't fall back to OpenAI (and doesn't require OPENAI_API_KEY).
    """
    try:
        # 1) Configure CrewAI LLM (Bedrock via LiteLLM model string).
        #
        # Default is derived from CHAT_MODEL_ID to keep configuration familiar.
        # Example default model string:
        #   bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0
        job.logger.info("ðŸ§  Starting CrewAI refactoring crew...")
        job.logger.info("ðŸ”§ Resolving Bedrock configuration...")
        region = normalize_aws_env(default_region="ap-southeast-2")
        model_id = resolve_bedrock_model_id()
        default_crewai_model = f"bedrock/{model_id}"
        crewai_model = os.getenv("CREWAI_MODEL", default_crewai_model)
        job.logger.info(f"ðŸŒŽ Bedrock region: {region}")
        job.logger.info(f"ðŸ¤– CrewAI model: {crewai_model}")

        # Help Bedrock provider resolution (different libs read different env vars).
        # (Already normalized above; keep for backward compatibility.)
        os.environ.setdefault("AWS_REGION", region)
        os.environ.setdefault("AWS_REGION_NAME", region)

        llm = LLM(
            model=crewai_model,
            temperature=0,
            timeout=float(os.getenv("CREWAI_TIMEOUT_SECONDS", "120")),
        )

        job.logger.info("ðŸ§© Creating agents...")

        architect = Agent(
            role="Senior Software Architect",
            goal="Analyze the code and propose a concise refactoring plan aligned with SOLID and clean architecture.",
            backstory="You are pragmatic and prioritize correctness, testability, and clear boundaries.",
            llm=llm,
            verbose=False,
            allow_delegation=False,
        )

        developer = Agent(
            role="Senior Python Developer",
            goal="Refactor the code according to the instruction and the architect plan, returning only valid Python code.",
            backstory="You write clean, typed Python and keep behavior changes minimal unless required by the instruction.",
            llm=llm,
            verbose=False,
            allow_delegation=False,
        )

        job.logger.info("ðŸ§ª Preparing tasks...")
        analysis_task = Task(
            description=(
                "Analyze the following Python code according to the user's instruction.\n"
                "Identify the top 3 critical issues (e.g., global state, lack of typing, tight coupling, poor naming).\n"
                "Then propose a short refactoring plan.\n\n"
                f"INSTRUCTION:\n{instruction}\n\n"
                f"CODE:\n{code}\n"
            ),
            expected_output="A bullet list of the top 3 issues and a short refactoring plan.",
            agent=architect,
        )

        refactor_task = Task(
            description=(
                "Refactor the code based on the architect analysis and the instruction.\n"
                "Use Python type hints and (only when appropriate) Pydantic models.\n"
                "Output ONLY the Python code. Do NOT wrap with markdown backticks.\n\n"
                f"INSTRUCTION:\n{instruction}\n\n"
                f"CODE:\n{code}\n"
            ),
            expected_output="Refactored Python code only (no markdown, no explanations).",
            agent=developer,
            context=[analysis_task],
        )

        job.logger.info("ðŸ§µ Building crew (sequential)...")
        crew = Crew(
            agents=[architect, developer],
            tasks=[analysis_task, refactor_task],
            process=Process.sequential,
            verbose=False,
        )

        # CrewAI kickoff is synchronous; run it off the event loop thread.
        job.logger.info("ðŸš€ Kickoff started (analysis â†’ refactor)...")

        # Capture any stdout/stderr from CrewAI internals (even if verbose=False).
        # This avoids noisy terminal spam while still surfacing errors/notes in logs.
        def _kickoff_captured():
            import io

            buf = io.StringIO()
            with contextlib.redirect_stdout(buf), contextlib.redirect_stderr(buf):
                out = crew.kickoff()
            return out, buf.getvalue()

        crew_output, kickoff_io = await asyncio.to_thread(_kickoff_captured)

        # Prefer the final task output, but fall back gracefully.
        job.logger.info("ðŸ“¦ Kickoff finished, extracting final code...")
        if kickoff_io and kickoff_io.strip():
            # Keep this bounded so we don't blow up the UI.
            tail = kickoff_io.strip().splitlines()[-50:]
            job.logger.info("ðŸªµ Crew output (tail):")
            for line in tail:
                job.logger.info(line)

        final_code = None
        try:
            tasks_output = getattr(crew_output, "tasks_output", None) or []
            if tasks_output:
                final_code = getattr(tasks_output[-1], "raw", None)
        except Exception:
            final_code = None
        final_code = (final_code or getattr(crew_output, "raw", "") or "").strip()
        job.logger.info("âœ… Refactor completed successfully.")

        # HTML diff viewer
        from_lines = _extract_lines(code)
        to_lines = _extract_lines(final_code)
        html_diff = _html_diff_viewer(
            from_lines=from_lines,
            to_lines=to_lines,
        )

        return {
            "code": final_code,
            "html": "<div>"
            + "<h6 class='font-bold'>âœ… Refactoring Complete!</h6>"
            + "<br/>"
            + "<p>Here is the side-by-side comparison:</p>"
            + html_diff
            + "</div>",
        }

    except Exception as e:
        job.logger.error(f"âŒ [System] Error: {str(e)}")
        raise


@mcp.ingest(
    is_long_running=True,
    description="Refactors EXISTING Python code that the user provides. Use this ONLY when the user wants to refactor/improve/modify code they already have. Do NOT use this for generating new code, examples, or sample code. The user must provide existing code to refactor.",
    response_handling={
        "mode": "formatted",
        "template": "Refactoring job has started. JOB_ID: {value}.",
    },
)
async def start_refactoring_job(code_snippet: str, instruction: str, job: Job) -> str:
    """
    Submits a Python code snippet to the Engineering Crew for refactoring.
    Returns a Job ID immediately (does not wait for completion).
    """
    job.logger.info("ðŸ“¨ Job submitted.")
    # Run the refactoring crew in the background while Job manages status, result, and heartbeat
    job.run(_run_refactoring_crew(job, code_snippet, instruction))
    return job.id


@mcp.ingest(
    description="Checks the status of a refactoring job. Returns logs or the final result. Falls back to database if job not found in memory.",
    response_handling={"mode": "direct"},
)
async def get_job_status(job_id: str) -> Dict[str, Any]:
    """
    Checks the status of a refactoring job. Returns logs or the final result.
    Falls back to database if job not found in memory.
    """
    # Try in-memory first
    job = mcp.get_job(job_id)

    # If not in memory, try database
    if not job:
        job_data = await mcp.get_job_from_db(job_id)
        if not job_data:
            return {"error": "Job ID not found."}

        # Get logs from database
        logs = await mcp.get_job_logs_from_db(job_id, limit=100)
        tail_n = int(os.getenv("JOB_LOG_TAIL", "25"))
        tail = "\n".join(logs[-tail_n:]) if logs else "[no logs in database]"

        return {
            "status": job_data["status"],
            "logs": tail,
            "result": job_data.get("result"),
            "error": job_data.get("error"),
        }

    # Job found in memory - return live data
    tail_n = int(os.getenv("JOB_LOG_TAIL", "25"))
    logs = mcp.get_job_logs(job_id) or []
    tail = "\n".join(logs[-tail_n:]) if logs else "[no logs yet]"

    if job.status == "running":
        return {"status": "running", "logs": tail}
    elif job.status == "completed":
        # Include logs even on completion so callers don't miss the final wrap-up lines.
        return {"status": "completed", "logs": tail, "result": job.result or ""}
    else:
        return {"status": "failed", "logs": tail, "error": job.error or "Unknown error"}


@mcp.ingest()
async def get_jobs() -> list[Job]:
    """
    Checks the status of a refactoring job. Returns logs or the final result.
    """
    return [job.id for job in mcp.get_jobs()]


if __name__ == "__main__":
    mcp.run(transport="sse")
    # mcp.run()
